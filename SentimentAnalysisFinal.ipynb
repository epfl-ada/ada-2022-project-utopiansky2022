{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from empath import Empath \n",
    "lexicon = Empath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data of character metadata\n",
    "\n",
    "df_characters = pd.read_csv('Data/character.metadata.tsv', sep='\\t')\n",
    "df_characters.columns = ['Wikipedia movie ID', 'Freebase movie ID', 'Movie release date', 'Character name', 'Actor date of birth', 'Actor gender',\n",
    "                        'Actor height (in meters)', 'Actor ethnicity (Freebase ID)', 'Actor name', 'Actor age at movie release',\n",
    "                        'Freebase character/actor map ID', 'Freebase character ID', 'Freebase actor ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data of movie metadata\n",
    "\n",
    "df_movie = pd.read_csv('Data/movie.metadata.tsv', sep='\\t')\n",
    "df_movie.columns = ['Wikipedia movie ID', 'Freebase movie ID', 'Movie name', 'Movie release date', 'Movie box office revenue', 'Movie runtime',\n",
    "                    'Movie languages (Freebase ID)', 'Movie countries (Freebase ID)', 'Movie genres (Freebase ID)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_char_movie = pd.merge(left=df_characters, right=df_movie, how='inner', on= ['Wikipedia movie ID', 'Freebase movie ID', 'Movie release date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMdf = pd.read_csv('Data/Characters_Matched_DF_Clean.csv', sep='\\t',index_col = 0)\n",
    "CMdf.columns = ['Wikipedia movie ID', 'Character name', 'Agent Verbs', 'Patient Verbs', 'Attributes']\n",
    "CMdf.reset_index(inplace = True,drop=True)\n",
    "CMdf.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMdf = pd.merge(left= CMdf, right=df_char_movie, how='inner', on= ['Wikipedia movie ID', 'Character name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMdf_c = CMdf[['Wikipedia movie ID','Character name','Actor gender','Agent Verbs','Patient Verbs','Attributes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-b945a5400729>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CMdf_c['Agent Verbs'] = CMdf_c['Agent Verbs'].str.replace(',' ,' ')\n",
      "<ipython-input-18-b945a5400729>:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  CMdf_c['Agent Verbs'] = CMdf_c['Agent Verbs'].str.replace('[' ,'')\n",
      "<ipython-input-18-b945a5400729>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CMdf_c['Agent Verbs'] = CMdf_c['Agent Verbs'].str.replace('[' ,'')\n",
      "<ipython-input-18-b945a5400729>:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  CMdf_c['Agent Verbs'] = CMdf_c['Agent Verbs'].str.replace(']' ,'')\n",
      "<ipython-input-18-b945a5400729>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CMdf_c['Agent Verbs'] = CMdf_c['Agent Verbs'].str.replace(']' ,'')\n",
      "<ipython-input-18-b945a5400729>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CMdf_c['Agent Verbs'] = CMdf_c['Agent Verbs'].str.replace(\"'\" ,'')\n",
      "<ipython-input-18-b945a5400729>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CMdf_c['Patient Verbs'] = CMdf_c['Patient Verbs'].str.replace(',' ,' ')\n",
      "<ipython-input-18-b945a5400729>:9: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  CMdf_c['Patient Verbs'] = CMdf_c['Patient Verbs'].str.replace('[' ,'')\n",
      "<ipython-input-18-b945a5400729>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CMdf_c['Patient Verbs'] = CMdf_c['Patient Verbs'].str.replace('[' ,'')\n",
      "<ipython-input-18-b945a5400729>:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  CMdf_c['Patient Verbs'] = CMdf_c['Patient Verbs'].str.replace(']' ,'')\n",
      "<ipython-input-18-b945a5400729>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CMdf_c['Patient Verbs'] = CMdf_c['Patient Verbs'].str.replace(']' ,'')\n",
      "<ipython-input-18-b945a5400729>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CMdf_c['Patient Verbs'] = CMdf_c['Patient Verbs'].str.replace(\"'\" ,'')\n",
      "<ipython-input-18-b945a5400729>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CMdf_c['Attributes'] = CMdf_c['Attributes'].str.replace(',' ,' ')\n",
      "<ipython-input-18-b945a5400729>:13: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  CMdf_c['Attributes'] = CMdf_c['Attributes'].str.replace('[' ,'')\n",
      "<ipython-input-18-b945a5400729>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CMdf_c['Attributes'] = CMdf_c['Attributes'].str.replace('[' ,'')\n",
      "<ipython-input-18-b945a5400729>:14: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  CMdf_c['Attributes'] = CMdf_c['Attributes'].str.replace(']' ,'')\n",
      "<ipython-input-18-b945a5400729>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CMdf_c['Attributes'] = CMdf_c['Attributes'].str.replace(']' ,'')\n",
      "<ipython-input-18-b945a5400729>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CMdf_c['Attributes'] = CMdf_c['Attributes'].str.replace(\"'\" ,'')\n"
     ]
    }
   ],
   "source": [
    "#our lexicon.analyze requires a string of words with a space between them. \n",
    "# to transform current AV,PV, Attributes into required format: \n",
    "\n",
    "CMdf_c['Agent Verbs'] = CMdf_c['Agent Verbs'].str.replace(',' ,' ')\n",
    "CMdf_c['Agent Verbs'] = CMdf_c['Agent Verbs'].str.replace('[' ,'')\n",
    "CMdf_c['Agent Verbs'] = CMdf_c['Agent Verbs'].str.replace(']' ,'')\n",
    "CMdf_c['Agent Verbs'] = CMdf_c['Agent Verbs'].str.replace(\"'\" ,'')\n",
    "CMdf_c['Patient Verbs'] = CMdf_c['Patient Verbs'].str.replace(',' ,' ')\n",
    "CMdf_c['Patient Verbs'] = CMdf_c['Patient Verbs'].str.replace('[' ,'')\n",
    "CMdf_c['Patient Verbs'] = CMdf_c['Patient Verbs'].str.replace(']' ,'')\n",
    "CMdf_c['Patient Verbs'] = CMdf_c['Patient Verbs'].str.replace(\"'\" ,'')\n",
    "CMdf_c['Attributes'] = CMdf_c['Attributes'].str.replace(',' ,' ')\n",
    "CMdf_c['Attributes'] = CMdf_c['Attributes'].str.replace('[' ,'')\n",
    "CMdf_c['Attributes'] = CMdf_c['Attributes'].str.replace(']' ,'')\n",
    "CMdf_c['Attributes'] = CMdf_c['Attributes'].str.replace(\"'\" ,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia movie ID</th>\n",
       "      <th>Character name</th>\n",
       "      <th>Actor gender</th>\n",
       "      <th>Agent Verbs</th>\n",
       "      <th>Patient Verbs</th>\n",
       "      <th>Attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>6469252</td>\n",
       "      <td>Nick Memphis</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>agent rookie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12588</th>\n",
       "      <td>848218</td>\n",
       "      <td>Pete Sandich</td>\n",
       "      <td>M</td>\n",
       "      <td>firefighter  makes  ai  take  refuses  decides...</td>\n",
       "      <td>inspired  assigned  sent</td>\n",
       "      <td>firefighter war fire retardant forest role ang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12199</th>\n",
       "      <td>6223567</td>\n",
       "      <td>Colthorpe</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aid nieces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12570</th>\n",
       "      <td>29735796</td>\n",
       "      <td>Uncle Albert</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>jovial arrival workshop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>2731003</td>\n",
       "      <td>Doug Barnum</td>\n",
       "      <td>M</td>\n",
       "      <td>caused  enlists  places</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deputy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7205</th>\n",
       "      <td>12751960</td>\n",
       "      <td>Bobby Mason</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kidnapped</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>29344186</td>\n",
       "      <td>Mike Flaherty</td>\n",
       "      <td>M</td>\n",
       "      <td>moonlights  let  moved  question  promised  of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>school team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7380</th>\n",
       "      <td>5476946</td>\n",
       "      <td>Betty Ross Banner</td>\n",
       "      <td>F</td>\n",
       "      <td>meets  claims  hopes  destroys  flees  done  ...</td>\n",
       "      <td>formed attacked</td>\n",
       "      <td>daughter plea moment orders forces team forces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14369</th>\n",
       "      <td>29663404</td>\n",
       "      <td>Jenny</td>\n",
       "      <td>F</td>\n",
       "      <td>gets  split  runs  ends  grabs  falls  tries  ...</td>\n",
       "      <td>chased  giving  seen</td>\n",
       "      <td>teenagers prom car friends face state woman mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8416</th>\n",
       "      <td>448735</td>\n",
       "      <td>Michael</td>\n",
       "      <td>M</td>\n",
       "      <td>preparing  agrees  begins  begins  appears  pr...</td>\n",
       "      <td>born  mistaken     interrupted astonished</td>\n",
       "      <td>roommate college plan brother friends friends ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia movie ID     Character name Actor gender  \\\n",
       "12443             6469252       Nick Memphis            M   \n",
       "12588              848218       Pete Sandich            M   \n",
       "12199             6223567          Colthorpe            M   \n",
       "12570            29735796       Uncle Albert            M   \n",
       "2491              2731003        Doug Barnum            M   \n",
       "7205             12751960        Bobby Mason            M   \n",
       "11607            29344186      Mike Flaherty            M   \n",
       "7380              5476946  Betty Ross Banner            F   \n",
       "14369            29663404              Jenny            F   \n",
       "8416               448735            Michael            M   \n",
       "\n",
       "                                             Agent Verbs  \\\n",
       "12443                                                NaN   \n",
       "12588  firefighter  makes  ai  take  refuses  decides...   \n",
       "12199                                                NaN   \n",
       "12570                                                      \n",
       "2491                             caused  enlists  places   \n",
       "7205                                                 NaN   \n",
       "11607  moonlights  let  moved  question  promised  of...   \n",
       "7380    meets  claims  hopes  destroys  flees  done  ...   \n",
       "14369  gets  split  runs  ends  grabs  falls  tries  ...   \n",
       "8416   preparing  agrees  begins  begins  appears  pr...   \n",
       "\n",
       "                                           Patient Verbs  \\\n",
       "12443                                                NaN   \n",
       "12588                           inspired  assigned  sent   \n",
       "12199                                                NaN   \n",
       "12570                                                      \n",
       "2491                                                 NaN   \n",
       "7205                                           kidnapped   \n",
       "11607                                                NaN   \n",
       "7380                                     formed attacked   \n",
       "14369                          chased  giving  seen        \n",
       "8416           born  mistaken     interrupted astonished   \n",
       "\n",
       "                                              Attributes  \n",
       "12443                                       agent rookie  \n",
       "12588  firefighter war fire retardant forest role ang...  \n",
       "12199                                         aid nieces  \n",
       "12570                            jovial arrival workshop  \n",
       "2491                                              deputy  \n",
       "7205                                             African  \n",
       "11607                                        school team  \n",
       "7380   daughter plea moment orders forces team forces...  \n",
       "14369  teenagers prom car friends face state woman mi...  \n",
       "8416   roommate college plan brother friends friends ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMdf_c.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test on lexicon.analyze : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' loses  passes  thwarts  follow  falls  thrashes  decides  has  returns  returns  interrupts  accepts'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMdf_c['Agent Verbs'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "social_media | 0.08333333333333333\n",
      "order | 0.08333333333333333\n",
      "fight | 0.08333333333333333\n",
      "competing | 0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "y = lexicon.analyze(CMdf_c['Agent Verbs'][1],normalize=True) #y is a dicitonary\n",
    "\n",
    "for key, value in y.items():\n",
    "    if value>0:\n",
    "        print(key, \"|\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attempting to incorporate the pope groups method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "women = CMdf_c.loc[CMdf_c['Actor gender'] == 'F']\n",
    "men = CMdf_c.loc[CMdf_c['Actor gender'] == 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cleaned and processed lexical information contains 9927 male characters and 5871 female characters\n"
     ]
    }
   ],
   "source": [
    "print('The cleaned and processed lexical information contains {} male characters and {} female characters'.format(len(men),len(women)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "women_lex_av = pd.DataFrame([lexicon.analyze(women['Agent Verbs'].str.cat(sep = ' '),normalize = True)])\n",
    "women_lex_pv = pd.DataFrame([lexicon.analyze(women['Patient Verbs'].str.cat(sep = ' '),normalize = True)])\n",
    "women_lex_att = pd.DataFrame([lexicon.analyze(women['Attributes'].str.cat(sep = ' '),normalize = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "men_lex_av = pd.DataFrame([lexicon.analyze(men['Agent Verbs'].str.cat(sep = ' '),normalize=True)])\n",
    "men_lex_pv = pd.DataFrame([lexicon.analyze(men['Patient Verbs'].str.cat(sep = ' '),normalize=True)])\n",
    "men_lex_att = pd.DataFrame([lexicon.analyze(men['Attributes'].str.cat(sep = ' '),normalize = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>help</th>\n",
       "      <th>office</th>\n",
       "      <th>dance</th>\n",
       "      <th>money</th>\n",
       "      <th>wedding</th>\n",
       "      <th>domestic_work</th>\n",
       "      <th>sleep</th>\n",
       "      <th>medical_emergency</th>\n",
       "      <th>cold</th>\n",
       "      <th>hate</th>\n",
       "      <th>...</th>\n",
       "      <th>weapon</th>\n",
       "      <th>children</th>\n",
       "      <th>monster</th>\n",
       "      <th>ocean</th>\n",
       "      <th>giving</th>\n",
       "      <th>contentment</th>\n",
       "      <th>writing</th>\n",
       "      <th>rural</th>\n",
       "      <th>positive_emotion</th>\n",
       "      <th>musical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Agent Verb [F]</th>\n",
       "      <td>0.004219</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.008420</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.016344</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.007020</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.010122</td>\n",
       "      <td>0.002819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient Verb [F]</th>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.025420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012559</td>\n",
       "      <td>0.018914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute [F]</th>\n",
       "      <td>0.029862</td>\n",
       "      <td>0.017149</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.097392</td>\n",
       "      <td>0.032375</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>0.011886</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.178079</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.007451</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.058305</td>\n",
       "      <td>0.009580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agent Verb [M]</th>\n",
       "      <td>0.003890</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.010081</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.006709</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient Verb [M]</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>0.016141</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute [M]</th>\n",
       "      <td>0.032596</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>0.070820</td>\n",
       "      <td>0.025504</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.007841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.112622</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.049044</td>\n",
       "      <td>0.009023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      help    office     dance     money   wedding  \\\n",
       "Agent Verb [F]    0.004219  0.001046  0.005212  0.001684  0.008420   \n",
       "Patient Verb [F]  0.000454  0.000000  0.000000  0.003026  0.025420   \n",
       "Attribute [F]     0.029862  0.017149  0.006327  0.003962  0.097392   \n",
       "Agent Verb [M]    0.003890  0.001019  0.004577  0.001800  0.008773   \n",
       "Patient Verb [M]  0.000000  0.000000  0.000000  0.003001  0.019547   \n",
       "Attribute [M]     0.032596  0.016465  0.005028  0.007525  0.070820   \n",
       "\n",
       "                  domestic_work     sleep  medical_emergency      cold  \\\n",
       "Agent Verb [F]         0.001418  0.002269           0.003989  0.000603   \n",
       "Patient Verb [F]       0.000000  0.000151           0.005296  0.000000   \n",
       "Attribute [F]          0.032375  0.005943           0.011886  0.001124   \n",
       "Agent Verb [M]         0.001571  0.001461           0.002327  0.000696   \n",
       "Patient Verb [M]       0.000162  0.000162           0.005191  0.000000   \n",
       "Attribute [M]          0.025504  0.005094           0.007758  0.001848   \n",
       "\n",
       "                      hate  ...    weapon  children   monster     ocean  \\\n",
       "Agent Verb [F]    0.003563  ...  0.001950  0.016344  0.001188  0.000709   \n",
       "Patient Verb [F]  0.002572  ...  0.012559  0.018914  0.000000  0.000000   \n",
       "Attribute [F]     0.005440  ...  0.002424  0.178079  0.002247  0.001774   \n",
       "Agent Verb [M]    0.004399  ...  0.004705  0.010081  0.001002  0.000807   \n",
       "Patient Verb [M]  0.001866  ...  0.016222  0.016141  0.000162  0.000000   \n",
       "Attribute [M]     0.007841  ...  0.009972  0.112622  0.004328  0.006409   \n",
       "\n",
       "                    giving  contentment   writing     rural  positive_emotion  \\\n",
       "Agent Verb [F]    0.007020     0.000638  0.001081  0.000709          0.010122   \n",
       "Patient Verb [F]  0.029354     0.000000  0.000757  0.000000          0.002270   \n",
       "Attribute [F]     0.004938     0.002484  0.007451  0.003075          0.058305   \n",
       "Agent Verb [M]    0.006709     0.000586  0.001673  0.000594          0.007864   \n",
       "Patient Verb [M]  0.021737     0.000000  0.001541  0.000000          0.002596   \n",
       "Attribute [M]     0.004678     0.001282  0.005377  0.002680          0.049044   \n",
       "\n",
       "                   musical  \n",
       "Agent Verb [F]    0.002819  \n",
       "Patient Verb [F]  0.000000  \n",
       "Attribute [F]     0.009580  \n",
       "Agent Verb [M]    0.003100  \n",
       "Patient Verb [M]  0.000000  \n",
       "Attribute [M]     0.009023  \n",
       "\n",
       "[6 rows x 194 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gendered_lex = pd.concat([women_lex_av, women_lex_pv, women_lex_att, men_lex_av, men_lex_pv, men_lex_att], ignore_index=True)\n",
    "gendered_lex.rename(index={0:\"Agent Verb [F]\", 1:\"Patient Verb [F]\", 2: \"Attribute [F]\" ,3:\"Agent Verb [M]\", 4:\"Patient Verb [M]\", 5: \"Attribute [M]\"}, inplace = True)\n",
    "gendered_lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate</th>\n",
       "      <th>monster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Agent Verb [F]</th>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.001188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient Verb [F]</th>\n",
       "      <td>0.002572</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute [F]</th>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.002247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agent Verb [M]</th>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient Verb [M]</th>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute [M]</th>\n",
       "      <td>0.007841</td>\n",
       "      <td>0.004328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      hate   monster\n",
       "Agent Verb [F]    0.003563  0.001188\n",
       "Patient Verb [F]  0.002572  0.000000\n",
       "Attribute [F]     0.005440  0.002247\n",
       "Agent Verb [M]    0.004399  0.001002\n",
       "Patient Verb [M]  0.001866  0.000162\n",
       "Attribute [M]     0.007841  0.004328"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gendered_lex[['hate','monster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agent Verb [F]</th>\n",
       "      <th>Patient Verb [F]</th>\n",
       "      <th>Attribute [F]</th>\n",
       "      <th>Agent Verb [M]</th>\n",
       "      <th>Patient Verb [M]</th>\n",
       "      <th>Attribute [M]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.010303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>0.024287</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.006109</td>\n",
       "      <td>0.016726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.005261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.009328</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.010634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.020209</td>\n",
       "      <td>0.054622</td>\n",
       "      <td>0.194577</td>\n",
       "      <td>0.019720</td>\n",
       "      <td>0.057669</td>\n",
       "      <td>0.128671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Agent Verb [F]  Patient Verb [F]  Attribute [F]  Agent Verb [M]  \\\n",
       "count      194.000000        194.000000     194.000000      194.000000   \n",
       "mean         0.002596          0.002734       0.011488        0.002467   \n",
       "std          0.003009          0.006128       0.024287        0.002733   \n",
       "min          0.000035          0.000000       0.000414        0.000068   \n",
       "25%          0.000625          0.000000       0.002513        0.000667   \n",
       "50%          0.001578          0.000303       0.004583        0.001338   \n",
       "75%          0.003492          0.002383       0.009328        0.003628   \n",
       "max          0.020209          0.054622       0.194577        0.019720   \n",
       "\n",
       "       Patient Verb [M]  Attribute [M]  \n",
       "count        194.000000     194.000000  \n",
       "mean           0.002761       0.010303  \n",
       "std            0.006109       0.016726  \n",
       "min            0.000000       0.000516  \n",
       "25%            0.000000       0.003067  \n",
       "50%            0.000324       0.005261  \n",
       "75%            0.002575       0.010634  \n",
       "max            0.057669       0.128671  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gendered_lex.transpose().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent Verb [F]      0.503625\n",
       "Patient Verb [F]    0.530337\n",
       "Attribute [F]       2.228668\n",
       "Agent Verb [M]      0.478680\n",
       "Patient Verb [M]    0.535648\n",
       "Attribute [M]       1.998701\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gendered_lex.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to go from here?\n",
    "* Create our own categories with ___lexicon.create_category___\n",
    "    + This is tricky: models based on nytimes, reddit, or fiction with varying degrees of utility depending on the word provided\n",
    "* Filter the existing categories for ones of interest\n",
    "* understand how their normalize works\n",
    "    + I figured each row of the gendered_df would sum to 1, which is not the case\n",
    "    + Perhaps we conduct our own normalization based on 9927 males and 5871 female characters\n",
    "    \n",
    "* for later: Check if we can get freq of occurrence of words --> top words by gender: clustering\n",
    "* occurrence of active vs passive m/f -> male gaze theory of passive women active men?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce99cf25ffd600a1bd039dd0e5fc1f91a501536a7e4709656cdce4bef5f7601c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
