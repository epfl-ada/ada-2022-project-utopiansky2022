{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a61866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nerea\\anaconda3\\envs\\ADA\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c9cd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: 193kB [00:00, 16.4MB/s]\n",
      "2022-11-11 10:21:07 INFO: Downloading default packages for language: en (English) ...\n",
      "2022-11-11 10:21:09 INFO: File exists: C:\\Users\\nerea\\stanza_resources\\en\\default.zip\n",
      "2022-11-11 10:21:21 INFO: Finished downloading models and saved to C:\\Users\\nerea\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download('en') # download English model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3add071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"\".join(x.strip() for x in text.split(\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ff5cdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:21:21 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: 193kB [00:00, 23.7MB/s]\n",
      "2022-11-11 10:21:21 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2022-11-11 10:21:24 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-11-11 10:21:24 INFO: Use device: cpu\n",
      "2022-11-11 10:21:24 INFO: Loading: tokenize\n",
      "2022-11-11 10:21:24 INFO: Loading: pos\n",
      "2022-11-11 10:21:25 INFO: Loading: lemma\n",
      "2022-11-11 10:21:25 INFO: Loading: depparse\n",
      "2022-11-11 10:21:25 INFO: Loading: ner\n",
      "2022-11-11 10:21:27 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize, mwt, pos, lemma, depparse, ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0951a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''The nation of Panem consists of a wealthy Capitol and twelve poorer districts. As punishment for a past rebellion, each district must provide a boy and girl between the ages of 12 and 18 selected by lottery for the annual Hunger Games. The tributes must fight to the death in an arena; the sole survivor is rewarded with fame and wealth. In her first Reaping, 12-year-old Primrose Everdeen is chosen from District 12. Her older sister Katniss volunteers to take her place. Peeta Mellark, a baker's son who once gave Katniss bread when she was starving, is the other District 12 tribute. Katniss and Peeta are taken to the Capitol, accompanied by their frequently drunk mentor, past victor Haymitch Abernathy. He warns them about the \"Career\" tributes who train intensively at special academies and almost always win. During a TV interview with Caesar Flickerman, Peeta unexpectedly reveals his love for Katniss.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3402bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc = nlp(text) # run annotation over a sentence\n",
    "#print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69a81069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_characters(doc):\n",
    "    characters = []\n",
    "    characters_name = []\n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.ents:\n",
    "            if word.type == 'PERSON' and word.text not in characters:\n",
    "                characters.append([word.text])\n",
    "                characters_name.append([word.text.split(' ')[0]])\n",
    "    characters = list(np.unique(characters))\n",
    "    characters_name = list(np.unique(characters_name))\n",
    "    return characters, characters_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a31efa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function finds attributes recursively, by first checking the words in \n",
    "the sentence which are not roots (main verb), and then checking all adjectives\n",
    "and conjunctions related to those words'''\n",
    "\n",
    "def recursive_find_adjs(root, sentence):\n",
    "    children = [w for w in sentence.words if w.head == root.id]\n",
    "    if not children:\n",
    "        pass \n",
    "    filtered_child = [w for w in children if (w.deprel == \"conj\" or w.deprel == \"compound\" or w.deprel == \"nsubj\") and (w.pos == \"ADJ\"or w.pos == 'NOUN')] #or w.pos == 'NOUN'\n",
    "    results = [w for w in filtered_child if not any(sub.head == w.id and sub.upos == \"NOUN\" for sub in sentence.words)]\n",
    "    for w in children:\n",
    "        results += recursive_find_adjs(w, sentence)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d41529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def char_attributes(doc):\n",
    "    names = []\n",
    "    names_2 = []\n",
    "    attributes = []\n",
    "    attributes_2 = []\n",
    "    for sent in doc.sentences:\n",
    "        nouns = [w for w in sent.words if w.pos == \"PROPN\"]\n",
    "        for noun in nouns:\n",
    "            if noun.text in get_characters(doc)[1]:\n",
    "                # Find constructions in the form of \"The car is beautiful\"\n",
    "                # In this scenario, the adjective is the parent of the noun\n",
    "                adj0 = sent.words[noun.head-1] #adjective directly related\n",
    "                adjs = [adj0] + recursive_find_adjs(adj0, sent) if adj0.pos == \"ADJ\" or adj0.pos == \"NOUN\" else []\n",
    "                #The recursive function finds adjectives related to the first one found,\n",
    "                #and hence also linked to the target noun\n",
    "                mod_adjs = [w for w in sent.words if w.head == noun.id and (w.pos == \"ADJ\")]\n",
    "                # This should only be one element because conjunctions are hierarchical\n",
    "                if mod_adjs:\n",
    "                    mod_adj = mod_adjs[0]\n",
    "                    adjs.extend([mod_adj] + recursive_find_adjs(mod_adj, sent))\n",
    "                if adjs:\n",
    "                    unique_adjs = []\n",
    "                    unique_ids = set()\n",
    "                    for adj in adjs:\n",
    "                        if adj.id not in unique_ids:\n",
    "                            unique_adjs.append(adj)\n",
    "                            unique_ids.add(adj.id)\n",
    "                    names.append(noun.text)\n",
    "                    attributes.append(\" \".join([adj.text for adj in unique_adjs]))\n",
    "    char_attributes = pd.DataFrame()\n",
    "    char_attributes['Character Names'] = names\n",
    "    char_attributes['Character Attributes'] = attributes\n",
    "    char_attributes['Total Attributes'] = char_attributes.groupby('Character Names')['Character Attributes'].transform(lambda x: ' '.join(x))\n",
    "    char_attributes= char_attributes[['Character Names','Total Attributes']]\n",
    "    return (char_attributes.drop_duplicates().reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "784462a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def agent_patient_verbs(doc):\n",
    "    agent_verbs = {'id': [], 'word': [], 'head_id': [], 'agent_verbs': []}\n",
    "    patient_verbs = {'id': [], 'word': [], 'head_id': [], 'patient_verbs': []}\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            if word.deprel == \"nsubj\" or word.deprel == \"acl:relcl\":\n",
    "                agent_verbs['id'].append(word.id)\n",
    "                agent_verbs['word'].append(word.text)\n",
    "                agent_verbs['head_id'].append(word.head)\n",
    "                agent_verbs['agent_verbs'].append(sentence.words[word.head-1].text)\n",
    "            elif word.deprel == \"nsubj:pass\" or word.deprel == \"dobj\" or word.deprel == \"iobj\":\n",
    "                patient_verbs['id'].append(word.id)\n",
    "                patient_verbs['word'].append(word.text)\n",
    "                patient_verbs['head_id'].append(word.head)\n",
    "                patient_verbs['patient_verbs'].append(sentence.words[word.head-1].text)\n",
    "\n",
    "    return (pd.DataFrame(data=agent_verbs), pd.DataFrame(data=patient_verbs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce78463e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_table_dependencies(plot):\n",
    "    doc = nlp(plot)\n",
    "    attrs_table = char_attributes(doc)\n",
    "    agent_verbs = agent_patient_verbs(doc)[0] \n",
    "    patient_verbs = agent_patient_verbs(doc)[1] \n",
    "    attrs_table['Agent Verbs'] = np.zeros(len(attrs_table['Character Names']))\n",
    "    attrs_table['Patient Verbs'] = np.zeros(len(attrs_table['Character Names']))\n",
    "    for idx, char in enumerate(attrs_table['Character Names']):\n",
    "        av = []\n",
    "        for idx2, w in enumerate(agent_verbs['word']):\n",
    "            if (w in attrs_table['Total Attributes'][idx] or w == char):\n",
    "                av.append(agent_verbs['agent_verbs'][idx2])\n",
    "                attrs_table['Agent Verbs'][idx] = av\n",
    "        pv = []\n",
    "        for idx2, w in enumerate(patient_verbs['word']):\n",
    "            if (w in attrs_table['Total Attributes'][idx] or w == char):\n",
    "                pv.append(patient_verbs['patient_verbs'][idx2])\n",
    "                attrs_table['Patient Verbs'][idx] = pv\n",
    "    return attrs_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "754b4055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia movie ID</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231378</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595909</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wikipedia movie ID                                            Summary\n",
       "0            23890098  Shlykov, a hard-working taxi driver and Lyosha...\n",
       "1            31186339  The nation of Panem consists of a wealthy Capi...\n",
       "2            20663735  Poovalli Induchoodan  is sentenced for six yea...\n",
       "3             2231378  The Lemon Drop Kid , a New York City swindler,...\n",
       "4              595909  Seventh-day Adventist Church pastor Michael Ch..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.1: Loading the data:\n",
    "data_folder = './data/'\n",
    "df_plots = pd.read_csv(data_folder + \"plot_summaries.txt\", sep='\\t', header=None)\n",
    "df_plots.columns = ('Wikipedia movie ID', 'Summary')\n",
    "df_plots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "839c4731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyse_Plots(df_plots):\n",
    "    plot_analysis = pd.DataFrame()\n",
    "    chars = []\n",
    "    movies = []\n",
    "    averbs = []\n",
    "    pverbs = []\n",
    "    attrs = []\n",
    "    for i, summ in enumerate(df_plots['Summary']):\n",
    "        print('Plot analysed ', i, ' out of ', len(df_plots['Summary']))\n",
    "        male_gaze = create_table_dependencies(summ)\n",
    "        for j in range(len(male_gaze)):\n",
    "            movies.append(df_plots['Wikipedia movie ID'][i])\n",
    "            chars.append(male_gaze['Character Names'][j])\n",
    "            averbs.append(male_gaze['Agent Verbs'][j])\n",
    "            pverbs.append(male_gaze['Patient Verbs'][j])\n",
    "            attrs.append(male_gaze['Total Attributes'][j])\n",
    "    plot_analysis['Wikipedia movie ID'] = movies\n",
    "    plot_analysis['Character_Name'] = chars\n",
    "    plot_analysis['Agent Verbs'] = averbs\n",
    "    plot_analysis['Patient Verbs'] = pverbs\n",
    "    plot_analysis['Attributes'] = attrs\n",
    "    return plot_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1def9faf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot analysed  0  out of  42303\n",
      "Plot analysed  1  out of  42303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_11308\\2852341466.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attrs_table['Patient Verbs'][idx] = pv\n",
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_11308\\2852341466.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attrs_table['Agent Verbs'][idx] = av\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot analysed  2  out of  42303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_11308\\2852341466.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attrs_table['Agent Verbs'][idx] = av\n",
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_11308\\2852341466.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attrs_table['Patient Verbs'][idx] = pv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot analysed  3  out of  42303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_11308\\2852341466.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attrs_table['Agent Verbs'][idx] = av\n",
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_11308\\2852341466.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attrs_table['Patient Verbs'][idx] = pv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot analysed  4  out of  42303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_11308\\2852341466.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attrs_table['Agent Verbs'][idx] = av\n",
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_11308\\2852341466.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attrs_table['Patient Verbs'][idx] = pv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot analysed  5  out of  42303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_11308\\2852341466.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attrs_table['Patient Verbs'][idx] = pv\n",
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_11308\\2852341466.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attrs_table['Agent Verbs'][idx] = av\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot analysed  6  out of  42303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_11308\\2852341466.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attrs_table['Agent Verbs'][idx] = av\n",
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_11308\\2852341466.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attrs_table['Patient Verbs'][idx] = pv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot analysed  7  out of  42303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nerea\\AppData\\Local\\Temp\\ipykernel_11308\\2852341466.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  attrs_table['Agent Verbs'][idx] = av\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot analysed  8  out of  42303\n"
     ]
    }
   ],
   "source": [
    "df_NLP = Analyse_Plots(df_plots)  \n",
    "df_NLP.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NLP.to_csv(data_folder + \"Plot_NLP_Analysis.csv\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb71282",
   "metadata": {},
   "source": [
    "- problem with words separated by \"-\", does not recognize it as one single word...\n",
    "- people-people attribute duplicated (people attribute-people)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44b80e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a04086ede2c9fba8dded5ae1d3862c5ce141bc2778c1114f47c151057d7c332"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
